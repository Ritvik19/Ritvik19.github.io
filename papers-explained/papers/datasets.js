const datasets = [
  {
    title: "Obelics",
    link: "a581f8d909b6",
    date: "June 2023",
    description:
      "An open web-scale filtered dataset of interleaved image-text documents comprising 141M web pages, 353M associated images, and 115B text tokens, extracted from CommonCrawl.",
    tags: ["Datasets", "Multimodal Datasets", "HuggingFace"],
  },
  {
    title: "HelpSteer",
    link: "8653a643a462",
    date: "November 2023",
    description: 
      "A 37k-sample multi-attribute helpfulness dataset where each response is annotated not only for overall helpfulness but also for correctness, coherence, complexity, and verbosity, aiming to avoid artifacts like models equating length with quality.",
    tags: ["Datasets", "LLM Safety"],
  },
  {
    title: "Dolma",
    link: "a656169269cb",
    date: "January 2024",
    description:
      "An open corpus of three trillion tokens designed to support language model pretraining research.",
    tags: ["Datasets", "Language Model Datasets", "Olmo"],
  },
  {
    title: "Aya Dataset",
    link: "9e299ac74a19",
    date: "February 2024",
    description:
      "A human-curated instruction-following dataset that spans 65 languages, created to bridge the language gap in datasets for natural language processing.",
    tags: ["Datasets", "Multilingual Datasets", "Cohere"],
  },
  {
    title: "WebSight",
    link: "2905d0e14233",
    date: "March 2024",
    description:
      "A synthetic dataset consisting of 2M pairs of HTML codes and their corresponding screenshots, generated through LLMs, aimed to accelerate research for converting a screenshot into a corresponding HTML. ",
    tags: ["Datasets", "Multimodal Datasets", "HuggingFace"],
  },
  {
    title: "Cosmopedia",
    link: "5f7e81c76d14",
    date: "March 2024",
    description:
      "Synthetic Data containing over 30M files and 25B tokens, generated by Mixtral-8x7B-Instruct-v0., aimed to reproduce the training data for Phi-1.5.",
    tags: [
      "Datasets",
      "Language Model Datasets",
      "HuggingFace",
      "Synthetic Data",
    ],
  },
  {
    title: "RewardBench",
    link: "A benchmark dataset and code-base designed to evaluate reward models used in RLHF",
    date: "March 2024",
    description:
      "A benchmark dataset and code-base designed to evaluate reward models used in RLHF.",
    tags: ["Datasets", "LLM Evaluation"],
  },
  {
    title: "FineWeb",
    link: "280bbc08068b",
    date: "May 2024",
    description:
      "A large-scale dataset for pretraining LLMs, consisting of 15T tokens, shown to produce better-performing models than other open pretraining datasets.",
    tags: ["Datasets", "Language Model Datasets", "HuggingFace"],
  },
  {
    title: "HelpSteer 2",
    link: "041ceb1b6749",
    date: "June 2024",
    description:
      "An open-source helpfulness preference dataset of about 10k response pairs, designed for training reward models that align LLMs with human preferences, despite being an order of magnitude smaller than older datasets like HH-RLHF.",
    tags: ["Datasets", "LLM Safety"],  
  },
  {
    title: "Numina Math",
    link: "paper-explained-316-numinamath-40501ae9baac",
    date: "July 2024",
    description:
      "A public AI4Maths dataset, comprising 860,000 competition math problems and solutions, ranging from high-school to advanced competition levels, annotated with chain-of-thought traces. It aims to improve mathematical reasoning in LLMs and is instrumental in developing a model that won the 1st AIMO Progress Prize, demonstrating its effectiveness in advancing state-of-the-art mathematical reasoning models.",
    tags: ["Datasets", "Scientific Data"],
  },
  {
    title: "Cosmopedia v2",
    link: "5f7e81c76d14#5bab",
    date: "July 2024",
    description:
      "An enhanced version of Cosmopedia, with a lot of emphasis on prompt optimization.",
    tags: [
      "Datasets",
      "Language Model Datasets",
      "HuggingFace",
      "Synthetic Data",
    ],
  },
  {
    title: "Docmatix",
    link: "9f2731ff1654",
    date: "July 2024",
    description:
      "A massive dataset for DocVQA containing 2.4M images, 9.5M question-answer pairs, and 1.3M PDF documents, generated by taking transcriptions from the PDFA OCR dataset and using a Phi-3-small model to generate Q/A pairs. ",
    tags: ["Datasets", "Document Understanding", "HuggingFace"],
  },
  {
    title: "PixMo",
    link: "239d70abebff",
    date: "September 2024",
    description:
      "A high-quality dataset of detailed image descriptions collected through speech-based annotations, enabling the creation of more robust and accurate VLMs.",
    tags: ["Datasets", "Multimodal Datasets"],
  },
  {
    title: "Help Steer 2 Preference",
    link: "9e95fd369850",
    date: "October 2024",
    description:
      "A highâ€‘quality dataset originally designed for Regression-style reward modeling, where responses to prompts are rated on a Likert-5 scale for helpfulness and safety. It augments HelpSteer2 with matched preference annotations, ie directions, strengths, and human-written justifications, so it can also support Bradley-Terry style training, enabling the first controlled, head-to-head comparison between Bradley-Terry and Regression reward models.",
    tags: ["Datasets", "LLM Safety"],
  },
  {
    title: "OmniMath",
    link: "bd2687c23e81",
    date: "October 2024",
    description:
      "A comprehensive benchmark dataset designed to evaluate the mathematical reasoning abilities of LLMs at the Olympiad level, comprising 4428 competition-level problems across 33 sub-domains and 10 difficulty levels, with a rigorous evaluation process utilizing GPT-4o and an open-source verifier, OmniJudge, to address the limitations of existing benchmarks that are now easily solved by advanced LLMs.",
    tags: ["Datasets", "Scientific Data"],
  },
  {
    title: "Smol Talk",
    link: "a166d5f1facc#b5e3",
    date: "November 2024",
    description:
      "A synthetic instruction-following dataset comprising 1 million samples, built using a fine-tuned LLM on a diverse range of instruction-following datasets and then generating synthetic conversations using various prompts and instructions to improve instruction following, chat, and reasoning capabilities.",
    tags: ["Datasets", "Synthetic Data", "HuggingFace"],
  },
  {
    title: "Red Pajama V1",
    link: "4aced4a3ff72",
    date: "November 2024",
    description:
      "A reproduction of the LLaMA training dataset, built from seven sources (CommonCrawl, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange) totaling 1.2 trillion tokens. The reproduction process involved addressing gaps and ambiguities in the original LLaMA documentation, with some differences in data processing choices.",
    tags: ["Datasets"],
  },
  {
    title: "Red Pajama V2",
    link: "4aced4a3ff72#9376",
    date: "November 2024",
    description:
      "A massive, unfiltered web-based dataset derived from CommonCrawl, comprising over 100 trillion tokens in multiple languages. It includes various quality signals (natural language metrics, repetitiveness, content flags, ML heuristics, and deduplication data) as metadata, enabling flexible filtering and dataset creation for diverse downstream tasks.",
    tags: ["Datasets"],
  },
  {
    title: "OEIS Sequence Benchmark",
    link: "20b0eecb7d45",
    date: "November 2024",
    description:
      "A benchmark to evaluate LLMs on integer sequence generation tasks from the Online Encyclopedia of Integer Sequences (OEIS). It assesses models' abilities to generate Python code for these sequences without using lookup tables.",
    tags: ["Benchmark"],
  },
  {
    title: "MVTamperBench",
    link: "828a22e9e0b9",
    date: "December 2024",
    description:
      "A benchmark designed to evaluate the robustness of Multimodal Language Models against five prevalent video tampering techniques: rotation, masking, substitution, repetition, and dropping. It comprises 3.4K original videos expanded into over 17K tampered clips.",
    tags: ["Datasets", "Benchmark", "Multimodal Datasets"],
  },
  {
    title: "Big Math",
    link: "426eacadc021",
    date: "February 2025",
    description:
      "A dataset of over 250,000 high-quality math questions designed for reinforcement learning (RL) in language models, addressing the gap between data quality and quantity in existing math datasets. It details the rigorous filtering, cleaning, and curation process, including the creation of Big-Math-Reformulated (47,000 reformulated questions).",
    tags: ["Datasets", "Scientific Data"],
  },
  {
    title: "NaturalReasoning",
    link: "9356f510b0a4",
    date: "February 2025",
    description:
      "A 2.8M-question dataset of challenging, real-world reasoning problems automatically curated from pretraining corpora via backtranslation, covering diverse domains such as Mathematics, Physics, Computer Science, Economics & Business, Social Sciences, and more.",
    tags: ["Datasets", "Scientific Data"],
  },
  {
    title: "Numina Math 1.5",
    link: "40501ae9baac#e825",
    date: "February 2025",
    description:
      "An update over NuminaMath dataset containing approximately 900k competition-level math problems with Chain of Thought (CoT) solutions, sourced from Chinese high school exercises to international mathematics olympiads. It includes metadata like answer, problem_type, and question_type for each problem, and features manually curated data from olympiads, contests, and specific mathematical domains, while removing the synthetic dataset synthetic_amc.",
    tags: ["Datasets", "Scientific Data"],
  },
  {
    title: "HelpSteer 3",
    link: "e2ba71915370",
    date: "March 2025",
    description:
      "A dataset collected from over 7,000 annotators across 80+ regions, focused on diverse, open-ended general-domain tasks where ground-truth answers often do not exist. For each task, annotators provide rich textual feedback on response helpfulness and then edit the original responses using that feedback, enabling the training of dedicated Feedback and Edit models. These models are used in a three-stage inference-time pipeline: one model generates multiple initial drafts, a second model produces detailed feedback on those drafts, and a third model edits them accordingly.",
    tags: ["Datasets", "LLM Safety"],
  },
  {
    title: "OpenCodeReasoning",
    link: "0e0b4439324a",
    date: "April 2025",
    description:
      "A publicly available dataset containing 736,712 Python code solutions with accompanying reasoning traces, spanning 28,904 unique competitive programming questions generated by DeepSeek-R1, designed to enhance the reasoning capabilities of LLMs in coding tasks through SFT.",
    tags: ["Datasets", "Code Data"],
  },
  {
    title: "DeepMath",
    link: "496109878202",
    date: "April 2025",
    description:
      "A large-scale dataset of ~103K challenging math problems designed for training reasoning models via reinforcement learning or supervised finetuning. It features verifiable answers for rule-based RL, three distinct AI-generated solutions per problem for diverse training approaches, and rigorous decontamination against existing benchmarks to ensure evaluation integrity and promote generalizable reasoning.",
    tags: ["Datasets", "Scientific Data"],
  },
  {
    title: "Help Steer 3 Preference",
    link: "2ebd5725a525",
    date: "May 2025",
    description:
      "A human-annotated preference dataset of over 40,000 samples designed for training general-domain, instruction-following language models with RLHF. It focuses on high-quality, diverse, and commercially usable data across real-world tasks, including STEM, coding, multilingual, and general domains, using specialist annotators (with domain degrees, work experience, and language proficiency) to label responses from 17 language models on prompts drawn from sources like WildChat-1M and ShareGPT.",
    tags: ["Dataset", "LLM Safety"],
  },
  {
    title: "SweEval",
    link: "f779d7da1196",
    date: "May 2025",
    description:
      "A cross-lingual enterprise safety benchmark designed to evaluate Large Language Models (LLMs) in handling sensitive language across diverse linguistic and cultural contexts. It assesses whether LLMs comply with or resist inappropriate instructions, such as including swear words, and evaluates their alignment with ethical frameworks, cultural nuances.",
    tags: ["Datasets", "Benchmark"],
  },
  {
    title: "Reasoning Gym",
    link: "3202ebfddeec",
    date: "May 2025",
    description:  
      "A comprehensive library of procedurally generated reasoning environments designed for RLVR training. It offers over 100 algorithmically verifiable tasks spanning diverse domains, allowing for unlimited training data with adjustable complexity and enabling researchers to study reasoning model development systematically.",
    tags: ["Datasets", "Environment", "Scientific Data"],
  },
  {
    title: "OpenThoughts",
    link: "51fcf3dda8d2",
    date: "June 2025",
    description:
      "The OpenThoughts project aims to create open-source datasets for training reasoning models, leading to the development of OpenThinker models.",
    tags: ["Datasets", "Scientific Data", "Open Source"],
  },
  {
    title: "OMEGA",
    link: "ac4abe71a794",
    date: "June 2025",
    description:
      "A benchmark to evaluate LLMs' out-of-distribution generalization in math across exploratory, compositional, and transformative axes. Experiments using OMEGA reveal that while LLMs show some improvement in exploratory generalization with fine-tuning, they struggle with compositional and transformative reasoning, highlighting a gap between LLM reasoning and human mathematical creativity.",
    tags: ["Datasets", "Benchmark", "Scientific Data"],
  },
  {
    title: "TabArena",
    link: "ff7e5159e982",
    date: "June 2025",
    description:
      "A continuously maintained, living benchmark for tabular machine learning models, featuring a curated collection of 51 datasets, 16 models, focusing on tabular classification and regression for independent and identically distributed (IID) data in the small to medium data regime.",
    tags: ["Datasets", "Benchmark", "Tabular Data"],
  },
  {
    title: "FineWeb 2",
    link: "d9126117600e",
    date: "June 2025",
    description:
      "A 20TB (5B document) multilingual dataset covering over 1000 languages, created using a new pre-training dataset curation pipeline based on FineWeb that can be automatically adapted to support any language. The pipeline includes steps for Language Identification, Deduplication, Filtering, and Dedup-informed upsampling (Rehydration), each of which improves performance.",
    tags: ["Datasets", "HuggingFace"],
  },
  {
    title: "NaturalThoughts",
    link: "360e8075f17c",
    date: "July 2025",
    description:
      "Curates a high-quality dataset of reasoning traces curated by selecting examples from NaturalReasoning to improve the reasoning capabilities of smaller language models through supervised finetuning. The study demonstrates that scaling high-quality, diverse reasoning data and selecting difficult examples requiring diverse reasoning strategies are more effective for distilling reasoning skills, and that training with a mix of System-1 (final answer only) and System-2 (full reasoning traces) distillation improves inference-time efficiency.",
    tags: ["Datasets", "Scientific Data"],
  },
  {
    title: "OpenCodeReasoning II",
    link: "c1e27ef6fb5e",
    date: "July 2025",
    description:
      "A large-scale dataset containing 2.5 million question-solution-critique triples for approximately 35,000 unique programming questions, featuring reasoning CoTs for both solutions and critiques. It also includes an extension to the LiveCodeBench benchmark to support C++ programming.",
    tags: ["Datasets", "Code Data"],
  },
  {
    title: "MegaScience",
    link: "ffe3fe3a8040",
    date: "July 2025",
    description:
      "Introduces TextBookReasoning, a dataset of 650k reasoning questions extracted from 12k university-level science textbooks, and MegaScience, a 1.25 million instance dataset created by combining high-quality open-source datasets.",
    tags: ["Datasets", "Scientific Data"],
  },
  {
    title: "FineVision",
    link: "e4b1af24ecbf",
    date: "September 2025",
    description:
      "A multimodal dataset with 24 million samples, created by collecting over 200 datasets containing 17M images, 89M question-answer turns, and 10B answer tokens, totaling 5TB of high-quality data.",
    tags: ["Datasets", "Multimodal Datasets", "HuggingFace"],
  },
  {
    title: "FACTS Leaderboard",
    link: "2ad8cda79681",
    date: "December 2025",
    description: 
      "An online benchmarking suite designed to evaluate the factual accuracy of large language models (LLMs) across diverse scenarios. It aggregates performance on four sub-leaderboards: FACTS Multimodal (image-based questions), FACTS Parametric (closed-book factoid questions), FACTS Search (information-seeking scenarios using a search API), and FACTS Grounding v2 (long-form responses grounded in provided documents).",
    tags: ["Datasets", "Benchmark", "Factual Accuracy"],
  },
  {
    title: "Nemotron-Math",
    link: "6a956874571a",
    date: "December 2025",
    description:
      "A a large-scale mathematical reasoning dataset built from 85K challenging AoPS problems and 262K StackExchange-Math questions, yielding 7.5M long-form solution traces (up to 128K tokens) generated by gpt-oss-120b in three reasoning modes (high, medium, low), each with and without Python tool-integrated reasoning (TIR).",
    tags: ["Datasets", "Scientific Data"],
  }
];
