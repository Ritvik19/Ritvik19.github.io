const neural_network_layers = [
  {
    title: "Convolution Layer",
    link: "c083e7410cd3#4176",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Convolution"],
  },
  {
    title: "Pointwise Convolution",
    link: "c083e7410cd3#8f24",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Convolution"],
  },
  {
    title: "Depthwise Convolution",
    link: "c083e7410cd3#20e4",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Convolution"],
  },
  {
    title: "Separable Convolution",
    link: "c083e7410cd3#539f",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Convolution"],
  },
  {
    title: "Convolution Transpose",
    link: "c083e7410cd3#a302",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Convolution"],
  },
  {
    title: "Simple Recurrent",
    link: "ff2f224af059#e405",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Recurrent"],
  },
  {
    title: "LSTM",
    link: "ff2f224af059#0947",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Recurrent"],
  },
  {
    title: "GRU",
    link: "ff2f224af059#4571",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Recurrent"],
  },
  {
    title: "Scaled Dot Product Attention",
    link: "beeef323e7f5#c18c",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Attention"],
  },
  {
    title: "Multi Head Attention",
    link: "beeef323e7f5#be63",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Attention"],
  },
  {
    title: "Cross Attention",
    link: "beeef323e7f5#0f28",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Attention"],
  },
  {
    title: "Causal Attention",
    link: "beeef323e7f5#14c7",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Attention"],
  },
  {
    title: "Sliding Window Attention",
    link: "beeef323e7f5#324c",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Attention"],
  },
  {
    title: "Multi Query Attention",
    link: "beeef323e7f5#0bfd",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Attention"],
  },
  {
    title: "Grouped Query Attention",
    link: "beeef323e7f5#d5fb",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Attention"],
  },
  {
    title: "Batch Normalisation",
    link: "56b556c9646e#00ea",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Normalization"],
  },
  {
    title: "Layer Normalisation",
    link: "56b556c9646e#9439",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Normalization"],
  },
  {
    title: "Instance Normalisation",
    link: "56b556c9646e#7783",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Normalization"],
  },
  {
    title: "Group Normalisation",
    link: "56b556c9646e#cd7f",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Normalization"],
  },
  {
    title: "Weight Standardisation",
    link: "56b556c9646e#3944",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Normalization"],
  },
  {
    title: "Batch Channel Normalisation",
    link: "56b556c9646e#3944",
    date: "",
    description: "",
    tags: ["Neural Network Layers", "Normalization"],
  },
];
