---
markmap:
  color: "#2980b9"
#   maxWidth: 400
#   initialExpandLevel: 4
---

# [A Survey on Data Synthesis and Augmentation for Large Language Models](https://arxiv.org/abs/2410.12896)

## Data Preparation
### General Model Distillation

#### Synthesize from Seeds
* Uses a small set of seed examples as prompts for LLMs to generate larger datasets. 
* This is cost-effective but can lack diversity if the seed set is too small. 
* Examples include TinyStories and Self-Instruct. Iterative approaches like Self-Instruct and Evol-Instruct address the diversity issue by repeatedly generating new instructions and examples.

#### Synthesize Reasoning Steps
* Focuses on improving LLM reasoning abilities by generating data with explicit reasoning steps. 
* Examples include MMIQC (adding reasoning steps to question-answer pairs) and MathInstruct (adding Program-of-Thought rationales). This helps train models to explain their reasoning process.

#### Synthesize with Controllability
* Aims to control the quality and characteristics of synthetic data to mitigate bias and ensure quality. 
* OSS-Instruct uses open-source code snippets to control the generation of coding problems, while DIALOGIC uses an auxiliary generator and filter to control dialogue generation. Genie uses content-example pairs to generate matching examples.

#### Synthesize from Scratch 
* Generates data without relying on seed datasets. 
* UltraChat generates questions on various topics from scratch, while Magpie constructs instruction data using pre-query templates. Generator prompts enhance diversity by having LLMs choose from a list of generated options. 
* This offers novelty but requires more sophisticated prompting.

#### Synthesize Multimodal Data
* Generates data involving multiple modalities like text and images. 
* ShareGPT4V generates image captions using GPT-4-vision, while StableLlava synchronously generates images and dialogues.
* ComVint addresses simplistic cross-modal instructions with a synthesis, complication, and reformulation pipeline. 
* Multi-modal Self-Instruct generates images and corresponding question-answer pairs from scratch. 
* ChartLlama generates chart data, figures, and instruction-answer pairs. 
* AnyInstruct-108k uses a two-stage approach involving text conversations with multimodal elements. 
* Genixer uses a holistic pipeline empowering Multimodal LLMs (MLLMs) for data generation.

### Data Augmentation

#### Data Labeling
* This can involve creating generalized prompt templates to guide the LLM's labeling process, generating dialogues that mimic existing conversations for annotation, or enhancing LLM annotations with additional information like audio features or image details. 
* Examples include using ChatGPT to annotate political affiliation of tweets and FullAnno which instructs LLMs to provide comprehensive annotations for images.

#### Data Reformation
* Transforming existing data into diverse variations using prompt engineering. 
* This includes generating problem variants (e.g., TinyGSM for math problems), creating counterfactual data by editing input text based on retrieved excerpts (e.g., CORE), and perturbing instances using linguistic processing and in-context learning (e.g., DISCO). 
* ALIA, for multi-modality, generates image captions, summarizes them into domain descriptions, and then uses these descriptions to create edited versions of the training data with Stable Diffusion.

#### Co-Annotation
* Combining human and LLM efforts for data annotation. 
* This can involve using human-written input-output examples to guide the LLM (e.g., Toolcoder), using LLMs to augment human annotation with relevant phrases and explanations, or dynamically allocating annotation tasks between humans and LLMs based on uncertainty levels (e.g., CoAnnotating). 
* Iterative co-annotation methods like Dialgen involve LLMs proposing candidate subdialogues, which are then validated, edited, and annotated by humans, with the process repeating until the dialogue is complete.

#### Non-LLM Driven Generation
* Generating synthetic data without LLMs. This includes using scripts and meticulously crafted modules to create math problems (e.g., AMPS), employing physics engines to generate ground-truth answers for physics problems (e.g., Mind's Eye), and filtering high-quality data from public resources (e.g., Proof-Pile-2). 
* Pruning strategies can also be used to remove redundancies in synthetic data.

## Pre-Training
### Model Self-Improvement
#### &nbsp;
* This technique uses the current version of an LLM to generate additional training data for itself. 
* For example, VILA-2 uses a self-augmenting process where the current model generates long, detailed captions which are then used for training the next iteration of the model.

### General Model Distillation
#### &nbsp;
* This involves leveraging powerful LLMs like GPT-3.5 and GPT-4 to generate high-quality synthetic data. Examples include:
* Phi-1: Uses synthetic code data generated by GPT-3.5, alongside filtered web data.
* Phi-1.5: Builds upon Phi-1 by adding new synthetic data for common sense reasoning tasks.
* TinyDialogues: Uses GPT-4 to generate realistic dialogues involving children.
* GLIDE: An open-source text-to-image generation model used to create synthetic image data, demonstrating its usefulness for classifier training and potentially model pre-training.

### Data Augmentation
#### Data Reformation: 
* This technique transforms existing data into a new, more diverse dataset. Examples include:
* WRAP: Uses an instruction-tuned model to paraphrase web documents in various styles, creating both real and synthetic rephrased data.
* bioR: Rewrites a synthetic dataset of biographies using Llama to create more realistic examples.
#### Non-LLM Driven Data Augmentation
* This involves augmenting datasets without using LLMs. Examples include:
* Proof-Pile-2: A 55B-token dataset augmented with scientific papers and web data, used for pre-training Code Llama (resulting in LLEMMA).
* KMLM: Uses massive multilingual knowledge graph triples converted into sequential data.
* Physics-based Modeling Framework: Generates synthetic data based on physics principles to ensure the LLM aligns with a physically consistent initial state. This is particularly useful for training models in scientific domains.
* SciLitLLM Data Filtering: While not strictly generation, this method uses Llama3-7B-Instruct to correct errors in parsed PDF data and then filters low-quality text using a classifier, effectively creating a higher-quality synthetic dataset from a noisy original source. This is a form of data refinement that contributes to the overall synthetic data pipeline.

##  Fine-Tuning
### Model Self-Improvement
### General Model Distillation
### Data Augmentation

## Instruction-Tuning
### General Model Distillation
### Model Self-Improvement
### Data Augmentation

##  Preference Alignment
### General Model Distillation
### Domain Model Distillation
### Model Self-Improvement
### Data Augmentation.

## Applications
### Math
### Science
### Code
### Medical
### Law

## Functionality
### Understanding
### Logic
### Memory
### Generation

## Challenges and Limitations
### Synthesizing and Augmenting Method
### Data Quality
### Impact of Data Synthesis and Augmentation
### Impact on Different Applications and Tasks
###  Future Directions